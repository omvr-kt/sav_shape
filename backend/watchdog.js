#!/usr/bin/env node

/**
 * WATCHDOG IND√âPENDANT POUR LE BACKEND SAV
 *
 * Ce watchdog tourne en continu et surveille la sant√© du backend.
 * Il red√©marre automatiquement le backend s'il ne r√©pond plus.
 *
 * Fonctionnalit√©s:
 * - V√©rifie le endpoint /api/health toutes les 30 secondes
 * - Red√©marre automatiquement le backend s'il est down
 * - Logs d√©taill√©s de toutes les actions
 * - G√®re les erreurs de r√©seau et timeouts
 * - √âvite les restart loops avec un backoff exponentiel
 */

const http = require('http');
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

// ============================================
// Configuration
// ============================================
const CONFIG = {
  BACKEND_URL: 'http://localhost:5000/api/health',
  CHECK_INTERVAL_NORMAL: 30000,        // 30 secondes en mode normal
  CHECK_INTERVAL_STARTUP: 5000,        // 5 secondes pendant le d√©marrage
  STARTUP_CHECKS: 6,                   // Nombre de v√©rifications rapides au d√©marrage (30s total)
  RESTART_TIMEOUT: 30000,              // Timeout pour le red√©marrage
  MAX_CONSECUTIVE_FAILURES: 3,         // Nombre d'√©checs avant red√©marrage
  BACKOFF_DELAY: 60000,                // D√©lai suppl√©mentaire apr√®s √©chec de restart (1 min)
  LOG_FILE: path.join(__dirname, 'logs', 'watchdog.log'),
  PM2_APP_NAME: 'sav-backend'
};

// ============================================
// √âtat du watchdog
// ============================================
let consecutiveFailures = 0;
let checkCount = 0;
let lastRestartTime = 0;
let isStartupPhase = true;

// ============================================
// Utilitaires
// ============================================

/**
 * Logger avec timestamp et sauvegarde dans fichier
 */
function log(level, message) {
  const timestamp = new Date().toISOString();
  const logMessage = `[${timestamp}] [${level}] ${message}`;

  console.log(logMessage);

  try {
    // S'assurer que le dossier logs existe
    const logDir = path.dirname(CONFIG.LOG_FILE);
    if (!fs.existsSync(logDir)) {
      fs.mkdirSync(logDir, { recursive: true });
    }

    fs.appendFileSync(CONFIG.LOG_FILE, logMessage + '\n');
  } catch (err) {
    console.error('Erreur √©criture log:', err.message);
  }
}

/**
 * V√©rifier si le backend r√©pond
 */
function checkBackendHealth() {
  return new Promise((resolve) => {
    const req = http.get(CONFIG.BACKEND_URL, { timeout: 5000 }, (res) => {
      let data = '';

      res.on('data', (chunk) => {
        data += chunk;
      });

      res.on('end', () => {
        if (res.statusCode === 200) {
          try {
            const health = JSON.parse(data);
            resolve({
              success: true,
              status: res.statusCode,
              data: health
            });
          } catch (e) {
            resolve({
              success: true,
              status: res.statusCode
            });
          }
        } else {
          resolve({
            success: false,
            status: res.statusCode,
            error: `HTTP ${res.statusCode}`
          });
        }
      });
    });

    req.on('error', (err) => {
      resolve({
        success: false,
        error: err.message
      });
    });

    req.on('timeout', () => {
      req.destroy();
      resolve({
        success: false,
        error: 'Timeout'
      });
    });
  });
}

/**
 * Red√©marrer le backend via PM2
 */
async function restartBackend() {
  const now = Date.now();
  const timeSinceLastRestart = now - lastRestartTime;

  // √âviter les red√©marrages trop fr√©quents
  if (timeSinceLastRestart < CONFIG.BACKOFF_DELAY) {
    const waitTime = Math.ceil((CONFIG.BACKOFF_DELAY - timeSinceLastRestart) / 1000);
    log('WARN', `Attente de ${waitTime}s avant le prochain red√©marrage (cooldown)...`);
    return false;
  }

  log('INFO', `üîÑ Tentative de red√©marrage du backend...`);
  lastRestartTime = now;

  try {
    // V√©rifier si le processus PM2 existe
    try {
      execSync(`pm2 describe ${CONFIG.PM2_APP_NAME}`, {
        stdio: 'pipe',
        timeout: 5000
      });

      // Le processus existe, on le restart
      log('INFO', 'Red√©marrage du processus existant...');
      execSync(`pm2 restart ${CONFIG.PM2_APP_NAME}`, {
        stdio: 'pipe',
        timeout: CONFIG.RESTART_TIMEOUT
      });

    } catch (describeErr) {
      // Le processus n'existe pas, on le d√©marre
      log('INFO', 'Processus non trouv√©, d√©marrage depuis ecosystem.config.js...');
      const backendDir = path.resolve(__dirname);
      execSync(`cd ${backendDir} && pm2 start ecosystem.config.js`, {
        stdio: 'pipe',
        timeout: CONFIG.RESTART_TIMEOUT
      });
    }

    // Sauvegarder la config PM2
    execSync('pm2 save --force', {
      stdio: 'pipe',
      timeout: 5000
    });

    log('INFO', '‚úÖ Commande de red√©marrage ex√©cut√©e avec succ√®s');

    // Attendre un peu pour que le backend d√©marre
    await new Promise(resolve => setTimeout(resolve, 5000));

    // V√©rifier que le backend est bien up
    const health = await checkBackendHealth();

    if (health.success) {
      log('INFO', '‚úÖ Backend red√©marr√© et op√©rationnel');
      consecutiveFailures = 0;
      isStartupPhase = true; // Repasser en phase de d√©marrage
      checkCount = 0;
      return true;
    } else {
      log('ERROR', `‚ùå Backend red√©marr√© mais ne r√©pond pas: ${health.error}`);
      return false;
    }

  } catch (err) {
    log('ERROR', `‚ùå Erreur lors du red√©marrage: ${err.message}`);
    return false;
  }
}

/**
 * V√©rification principale
 */
async function performHealthCheck() {
  log('INFO', 'V√©rification du statut du backend...');

  const health = await checkBackendHealth();

  if (health.success) {
    log('INFO', `‚úÖ Backend actif et sain`);
    consecutiveFailures = 0;

    // Transition vers le mode normal apr√®s la phase de d√©marrage
    if (isStartupPhase) {
      checkCount++;
      if (checkCount >= CONFIG.STARTUP_CHECKS) {
        isStartupPhase = false;
        log('INFO', 'üéØ Phase de d√©marrage termin√©e, passage au mode surveillance normal');
      }
    }

  } else {
    consecutiveFailures++;
    log('WARN', `‚ö†Ô∏è  Backend ne r√©pond pas (${consecutiveFailures}/${CONFIG.MAX_CONSECUTIVE_FAILURES}): ${health.error || 'Erreur inconnue'}`);

    // Red√©marrer apr√®s plusieurs √©checs cons√©cutifs
    if (consecutiveFailures >= CONFIG.MAX_CONSECUTIVE_FAILURES) {
      log('ERROR', `‚ùå Backend down apr√®s ${consecutiveFailures} √©checs cons√©cutifs`);

      const restarted = await restartBackend();

      if (!restarted) {
        log('ERROR', '‚ùå √âCHEC DU RED√âMARRAGE - alerte critique n√©cessaire');
      }

      consecutiveFailures = 0; // Reset pour √©viter les restart loops
    }
  }
}

/**
 * Boucle principale du watchdog
 */
async function mainLoop() {
  await performHealthCheck();

  // D√©terminer l'intervalle de la prochaine v√©rification
  const nextInterval = isStartupPhase
    ? CONFIG.CHECK_INTERVAL_STARTUP
    : CONFIG.CHECK_INTERVAL_NORMAL;

  const nextCheckIn = Math.ceil(nextInterval / 1000);
  log('INFO', `Prochaine v√©rification dans ${nextCheckIn}s`);

  setTimeout(mainLoop, nextInterval);
}

/**
 * Gestion des signaux pour arr√™t propre
 */
function setupSignalHandlers() {
  const signals = ['SIGTERM', 'SIGINT'];

  signals.forEach(signal => {
    process.on(signal, () => {
      log('INFO', `Signal ${signal} re√ßu, arr√™t du watchdog...`);
      process.exit(0);
    });
  });

  process.on('uncaughtException', (err) => {
    log('ERROR', `Exception non g√©r√©e: ${err.message}`);
    log('ERROR', err.stack);
  });

  process.on('unhandledRejection', (reason, promise) => {
    log('ERROR', `Promise rejet√©e non g√©r√©e: ${reason}`);
  });
}

/**
 * D√©marrage du watchdog
 */
function start() {
  log('INFO', '========================================');
  log('INFO', 'üöÄ D√âMARRAGE DU WATCHDOG BACKEND SAV');
  log('INFO', '========================================');
  log('INFO', `URL surveill√©e: ${CONFIG.BACKEND_URL}`);
  log('INFO', `Intervalle startup: ${CONFIG.CHECK_INTERVAL_STARTUP / 1000}s`);
  log('INFO', `Intervalle normal: ${CONFIG.CHECK_INTERVAL_NORMAL / 1000}s`);
  log('INFO', `Seuil d'√©checs: ${CONFIG.MAX_CONSECUTIVE_FAILURES}`);
  log('INFO', '========================================');

  setupSignalHandlers();
  mainLoop();
}

// D√©marrer le watchdog
start();
